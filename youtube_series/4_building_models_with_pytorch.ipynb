{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWKC6rNUDfw/V5i7YSBOpe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimsooyoung/pytorch_til/blob/main/youtube_series/4_building_models_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `torch.nn`.Module and `torch.nn.Parameter`\n",
        "\n",
        "One important behavior of torch.nn.Module is registering parameters. If a particular Module subclass has learning weights, these weights are expressed as instances of `torch.nn.Parameter`. The Parameter class is a subclass of torch.Tensor, with the special behavior that when they are assigned as attributes of a Module, they are added to the list of that modules parameters. These parameters may be accessed through the `parameters()` method on the Module class.\n",
        "\n",
        "\n",
        "As a simple example, here’s a very simple model with two linear layers and an activation function. We’ll create an instance of it and ask it to report on its parameters:\n",
        "\n"
      ],
      "metadata": {
        "id": "A8nJRpsxjdg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class TinyModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(TinyModel, self).__init__()\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(100, 200)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.linear2 = torch.nn.Linear(200, 10)\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "tinymodel = TinyModel()\n",
        "\n",
        "print('The model:')\n",
        "print(tinymodel)\n",
        "\n",
        "print('\\n\\nJust one layer:')\n",
        "print(tinymodel.linear2)\n",
        "\n",
        "print('\\n\\nModel params:')\n",
        "for param in tinymodel.parameters():\n",
        "    print(param)\n",
        "\n",
        "print('\\n\\nLayer params:')\n",
        "for param in tinymodel.linear2.parameters():\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hS9sS2vmdpp",
        "outputId": "3b95cfdd-1544-4897-ffb4-22b91a02bad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model:\n",
            "TinyModel(\n",
            "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
            "  (activation): ReLU()\n",
            "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n",
            "\n",
            "\n",
            "Just one layer:\n",
            "Linear(in_features=200, out_features=10, bias=True)\n",
            "\n",
            "\n",
            "Model params:\n",
            "Parameter containing:\n",
            "tensor([[ 0.0422, -0.0064, -0.0296,  ..., -0.0506, -0.0024,  0.0316],\n",
            "        [ 0.0690,  0.0997, -0.0809,  ..., -0.0023,  0.0551, -0.0145],\n",
            "        [-0.0646,  0.0662,  0.0890,  ..., -0.0688,  0.0827,  0.0901],\n",
            "        ...,\n",
            "        [ 0.0178,  0.0048, -0.0026,  ...,  0.0307,  0.0820, -0.0692],\n",
            "        [ 0.0379, -0.0731, -0.0311,  ..., -0.0770, -0.0619,  0.0920],\n",
            "        [-0.0068, -0.0298, -0.0436,  ...,  0.0265,  0.0568, -0.0203]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 6.3280e-02,  9.3010e-02, -7.3512e-02,  9.1296e-03, -1.3778e-02,\n",
            "         1.0001e-02, -7.3201e-02, -5.1876e-02, -4.6833e-02, -5.9591e-03,\n",
            "         9.2902e-02, -1.6865e-02,  4.9538e-02, -2.2501e-02, -6.5997e-02,\n",
            "        -8.6336e-02, -2.7478e-02,  1.3378e-02,  5.7419e-02,  4.3306e-03,\n",
            "        -3.6546e-02, -1.0927e-02,  7.9583e-02,  6.3676e-02, -7.0992e-02,\n",
            "        -8.6369e-02, -2.8015e-02,  4.9799e-02,  4.3705e-02,  5.0589e-02,\n",
            "         8.7594e-02, -9.3089e-02,  2.2337e-02,  1.3079e-02, -6.2429e-02,\n",
            "        -8.4746e-02, -9.8954e-02, -7.6213e-02,  8.1315e-02,  3.0597e-03,\n",
            "        -6.2784e-02,  9.0200e-02, -7.7134e-02, -7.6176e-02,  5.5210e-02,\n",
            "         9.9072e-02, -2.8942e-02, -6.0641e-02,  1.0507e-02, -4.1208e-02,\n",
            "        -5.6214e-02,  3.9035e-02, -3.2012e-02, -4.6874e-02,  5.4260e-02,\n",
            "        -4.7384e-02, -2.4084e-02,  1.8287e-05,  2.3142e-02,  6.4508e-02,\n",
            "        -4.7740e-02,  9.4249e-02, -2.7407e-03, -8.8539e-02,  8.4369e-03,\n",
            "        -1.6314e-02,  1.8734e-02,  9.6484e-02, -5.1291e-02, -1.1095e-02,\n",
            "        -4.6419e-03,  1.3082e-02, -5.7669e-02, -5.3439e-02, -1.3418e-02,\n",
            "        -9.9484e-02, -9.0560e-02, -2.1101e-02, -6.9631e-02, -1.1935e-02,\n",
            "         6.6327e-02,  8.5868e-02, -5.6202e-02, -5.6952e-03, -8.1179e-02,\n",
            "        -9.8514e-02, -6.2555e-02, -5.1779e-02, -2.7949e-02, -1.0417e-02,\n",
            "         7.0254e-02, -4.1249e-02,  6.8777e-02, -4.6890e-02, -1.4577e-02,\n",
            "         7.5821e-02,  4.6475e-02,  3.9172e-02, -9.9200e-02,  4.2742e-03,\n",
            "        -8.5836e-02, -4.3615e-02,  1.6413e-02,  3.5508e-02,  2.3578e-02,\n",
            "         2.1190e-02, -8.5033e-02,  8.4685e-02,  9.5516e-02, -4.6304e-02,\n",
            "         9.2261e-02, -1.1852e-04,  2.3930e-02, -8.4595e-03,  5.1029e-02,\n",
            "         8.3901e-02,  3.2901e-03, -4.0848e-02,  4.6243e-03, -3.1932e-03,\n",
            "        -1.7611e-02, -6.8186e-03,  8.7628e-02,  5.9833e-02,  1.9315e-02,\n",
            "        -5.6906e-02, -1.8002e-02, -3.2887e-02, -3.8968e-02, -9.7302e-02,\n",
            "        -2.2562e-02, -1.9396e-02, -4.9255e-02, -1.6688e-02, -5.2287e-02,\n",
            "         2.2583e-02, -3.3703e-02, -7.9340e-02,  8.9530e-02, -2.5340e-02,\n",
            "        -5.4526e-02,  2.5494e-02, -5.7844e-02, -6.8654e-02, -5.5219e-02,\n",
            "        -5.8335e-02,  6.7554e-02, -1.1194e-03,  7.2921e-02, -1.7526e-02,\n",
            "         1.0557e-02,  7.5637e-02,  1.0718e-02, -3.6609e-02, -9.4746e-02,\n",
            "         4.5769e-02, -7.1669e-02,  9.3343e-02, -3.7563e-02,  5.8830e-02,\n",
            "         5.6205e-02,  6.6761e-02, -9.3996e-02, -9.3228e-02, -9.3053e-02,\n",
            "         5.9803e-03, -6.1218e-02,  2.4329e-02,  9.2313e-02,  6.3172e-02,\n",
            "         2.6226e-02,  9.5576e-02,  2.8357e-02,  8.3686e-02, -9.1144e-02,\n",
            "         1.9068e-02,  4.3816e-02,  3.2392e-02,  1.1560e-02,  3.6517e-03,\n",
            "         3.8580e-02,  9.3465e-02,  3.6785e-02, -4.3436e-03, -6.1902e-03,\n",
            "         4.8189e-03, -2.6946e-02,  3.5927e-02,  9.8532e-03, -5.9326e-03,\n",
            "         4.6222e-02,  7.7829e-03, -2.1060e-02,  9.9153e-02,  4.4528e-02,\n",
            "        -1.6033e-03, -1.7343e-02,  1.7046e-02,  4.0728e-02,  9.9594e-02],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0332,  0.0176, -0.0191,  ...,  0.0311,  0.0173,  0.0531],\n",
            "        [-0.0551, -0.0498, -0.0276,  ...,  0.0681,  0.0472,  0.0049],\n",
            "        [ 0.0257,  0.0629,  0.0683,  ...,  0.0017, -0.0625, -0.0629],\n",
            "        ...,\n",
            "        [-0.0426, -0.0392, -0.0241,  ...,  0.0261, -0.0151,  0.0155],\n",
            "        [ 0.0080,  0.0566, -0.0473,  ..., -0.0168,  0.0620, -0.0282],\n",
            "        [ 0.0686,  0.0513, -0.0238,  ...,  0.0435,  0.0666,  0.0280]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 1.7237e-02,  1.4376e-02, -3.0746e-02, -6.6169e-02, -4.4462e-02,\n",
            "        -8.6418e-05, -1.3232e-02, -6.1733e-02, -1.1533e-02, -3.3490e-02],\n",
            "       requires_grad=True)\n",
            "\n",
            "\n",
            "Layer params:\n",
            "Parameter containing:\n",
            "tensor([[-0.0332,  0.0176, -0.0191,  ...,  0.0311,  0.0173,  0.0531],\n",
            "        [-0.0551, -0.0498, -0.0276,  ...,  0.0681,  0.0472,  0.0049],\n",
            "        [ 0.0257,  0.0629,  0.0683,  ...,  0.0017, -0.0625, -0.0629],\n",
            "        ...,\n",
            "        [-0.0426, -0.0392, -0.0241,  ...,  0.0261, -0.0151,  0.0155],\n",
            "        [ 0.0080,  0.0566, -0.0473,  ..., -0.0168,  0.0620, -0.0282],\n",
            "        [ 0.0686,  0.0513, -0.0238,  ...,  0.0435,  0.0666,  0.0280]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 1.7237e-02,  1.4376e-02, -3.0746e-02, -6.6169e-02, -4.4462e-02,\n",
            "        -8.6418e-05, -1.3232e-02, -6.1733e-02, -1.1533e-02, -3.3490e-02],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> This shows the fundamental structure of a PyTorch model: there is an `__init__()` method that defines the layers and other components of a model, and a forward() method where the computation gets done. Note that we can print the model, or any of its submodules, to learn about its structure.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xn4F-vpimnvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common Layer Types\n",
        "\n",
        "## Linear Layers\n",
        "\n",
        "The most basic type of neural network layer is a linear or fully connected layer. This is a layer where every input influences every output of the layer to a degree specified by the layer’s weights. If a model has m inputs and n outputs, the weights will be an m x n matrix. For example:\n",
        "\n"
      ],
      "metadata": {
        "id": "Tr5l3VJ3mynz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin = torch.nn.Linear(3, 2)\n",
        "x = torch.rand(1, 3)\n",
        "print('Input : ')\n",
        "print(x)\n",
        "\n",
        "print('\\n\\nWeight and Bias parameters:')\n",
        "for param in lin.parameters():\n",
        "  print(param)\n",
        "\n",
        "y = lin(x)\n",
        "print('\\n\\nOutput:')\n",
        "print(y)"
      ],
      "metadata": {
        "id": "Ww3v88iTm1wK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d316cd99-5a4a-45d0-e625-dbaabd2a1ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : \n",
            "tensor([[0.2064, 0.6039, 0.0304]])\n",
            "\n",
            "\n",
            "Weight and Bias parameters:\n",
            "Parameter containing:\n",
            "tensor([[-0.2475,  0.0194, -0.5053],\n",
            "        [-0.4036, -0.1715, -0.2951]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0609, 0.4465], requires_grad=True)\n",
            "\n",
            "\n",
            "Output:\n",
            "tensor([[0.0062, 0.2507]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If you do the matrix multiplication of x by the linear layer’s weights, and add the biases, you’ll find that you get the output vector y.\n",
        "\n",
        "- One other important feature to note: When we checked the weights of our layer with lin.weight, it reported itself as a Parameter (which is a subclass of Tensor), and let us know that it’s tracking gradients with autograd. This is a default behavior for Parameter that differs from Tensor.\n",
        "\n",
        "- Linear layers are used widely in deep learning models. One of the most common places you’ll see them is in classifier models, which will usually have one or more linear layers at the end, where the last layer will have n outputs, where n is the number of classes the classifier addresses."
      ],
      "metadata": {
        "id": "l_mnmP2dQbDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Layers\n",
        "\n",
        "Convolutional layers are built to handle data with a high degree of spatial correlation. They are very commonly used in computer vision, where they detect close groupings of features which the compose into higher-level features. They pop up in other contexts too - for example, in NLP applications, where a word’s immediate context (that is, the other words nearby in the sequence) can affect the meaning of a sentence.\n",
        "\n",
        "> We saw convolutional layers in action in LeNet5 in an earlier video:"
      ],
      "metadata": {
        "id": "aNdOLQv2QpkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.functional as F\n",
        "\n",
        "\n",
        "class LeNet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = torch.nn.Linear(120, 84)\n",
        "        self.fc3 = torch.nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n"
      ],
      "metadata": {
        "id": "5bZX9BnpQtQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s break down what’s happening in the convolutional layers of this model. Starting with conv1:\n",
        "\n",
        "- LeNet5 is meant to take in a 1x32x32 black & white image. The first argument to a convolutional layer’s constructor is the number of input channels. Here, it is 1. If we were building this model to look at 3-color channels, it would be 3.\n",
        "\n",
        "- A convolutional layer is like a window that scans over the image, looking for a pattern it recognizes. These patterns are called features, and one of the parameters of a convolutional layer is the number of features we would like it to learn. This is the second argument to the constructor is the number of output features. Here, we’re asking our layer to learn 6 features.\n",
        "\n",
        "- Just above, I likened the convolutional layer to a window - but how big is the window? The third argument is the window or kernel size. Here, the “5” means we’ve chosen a 5x5 kernel. (If you want a kernel with height different from width, you can specify a tuple for this argument - e.g., (3, 5) to get a 3x5 convolution kernel.)"
      ],
      "metadata": {
        "id": "focRvvKlRKuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Layers\n",
        "\n",
        "Recurrent neural networks (or RNNs) are used for sequential data - anything from time-series measurements from a scientific instrument to natural language sentences to DNA nucleotides. An RNN does this by maintaining a hidden state that acts as a sort of memory for what it has seen in the sequence so far.\n",
        "\n"
      ],
      "metadata": {
        "id": "f1yJY4S1RfCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMTagger(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "metadata": {
        "id": "PEbYsWl9RmSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The constructor has four arguments:\n",
        "\n",
        "- `vocab_size` is the number of words in the input vocabulary. Each word is a one-hot vector (or unit vector) in a vocab_size-dimensional space.\n",
        "\n",
        "- `tagset_size` is the number of tags in the output set.\n",
        "\n",
        "- `embedding_dim` is the size of the embedding space for the vocabulary. An embedding maps a vocabulary onto a low-dimensional space, where words with similar meanings are close together in the space.\n",
        "\n",
        "- `hidden_dim` is the size of the LSTM’s memory."
      ],
      "metadata": {
        "id": "S-va0hqHSDLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers\n",
        "\n",
        "PyTorch has a Transformer class that allows you to define the overall parameters of a transformer model - the number of attention heads, the number of encoder & decoder layers, dropout and activation functions, etc.\n",
        "\n",
        "For details, check out the documentation on transformer classes, and the relevant [tutorial](https://pytorch.org/tutorials/beginner/transformer_tutorial.html) on pytorch.org."
      ],
      "metadata": {
        "id": "3MkiSoCfSGXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Layers and Functions\n",
        "\n",
        "### Data Manipulation Layers\n",
        "\n",
        "There are other layer types that perform important functions in models, but don’t participate in the learning process themselves. **Max pooling** (and its twin, min pooling) reduce a tensor by combining cells, and assigning the maximum value of the input cells to the output cell (we saw this). For example:\n",
        "\n"
      ],
      "metadata": {
        "id": "nhz3IAukSYco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 6, 6)\n",
        "print(my_tensor)\n",
        "\n",
        "maxpool_layer = torch.nn.MaxPool2d(3)\n",
        "print(maxpool_layer(my_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fprSw5vITD3q",
        "outputId": "7e902177-43fb-48c6-eae3-36011f1b6c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.5747, 0.6558, 0.6151, 0.5992, 0.7093, 0.6753],\n",
            "         [0.0551, 0.7878, 0.7702, 0.7950, 0.4861, 0.2960],\n",
            "         [0.2916, 0.8792, 0.8282, 0.3240, 0.9235, 0.2314],\n",
            "         [0.2363, 0.2916, 0.0016, 0.1204, 0.4170, 0.2871],\n",
            "         [0.0452, 0.8503, 0.6008, 0.2773, 0.8376, 0.4313],\n",
            "         [0.5447, 0.0856, 0.5336, 0.0569, 0.5850, 0.2095]]])\n",
            "tensor([[[0.8792, 0.9235],\n",
            "         [0.8503, 0.8376]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalization layers** re-center and normalize the output of one layer before feeding it to another. Centering the and scaling the intermediate tensors has a number of beneficial effects, such as letting you use higher learning rates without exploding/vanishing gradients.\n",
        "\n",
        "This is beneficial because many activation functions (discussed below) have their strongest gradients near 0, but sometimes suffer from vanishing or exploding gradients for inputs that drive them far away from zero. Keeping the data centered around the area of steepest gradient will tend to mean faster, better learning and higher feasible learning rates.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HOzCQIO-TFX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
        "print(my_tensor)\n",
        "\n",
        "print(my_tensor.mean())\n",
        "\n",
        "norm_layer = torch.nn.BatchNorm1d(4)\n",
        "normed_tensor = norm_layer(my_tensor)\n",
        "print(normed_tensor)\n",
        "\n",
        "print(normed_tensor.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou97_nopTZ_z",
        "outputId": "cf7dea1e-5db5-460e-8eb9-b7f8e156535b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 5.5855,  7.4518, 11.1203, 13.6877],\n",
            "         [23.0146, 18.0233,  9.5671, 17.6425],\n",
            "         [23.0110,  6.1079, 16.2284, 10.0754],\n",
            "         [17.3357, 23.6466,  6.8381,  7.0104]]])\n",
            "tensor(13.5216)\n",
            "tensor([[[-1.2307, -0.6381,  0.5268,  1.3420],\n",
            "         [ 1.2354,  0.1995, -1.5555,  0.1205],\n",
            "         [ 1.4308, -1.2109,  0.3708, -0.5908],\n",
            "         [ 0.5080,  1.3918, -0.9620, -0.9378]]],\n",
            "       grad_fn=<NativeBatchNormBackward0>)\n",
            "tensor(-2.9802e-08, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dropout layers** are a tool for encouraging sparse representations in your model - that is, pushing it to do inference with less data.\n",
        "\n",
        "\n",
        "Dropout layers work by randomly setting parts of the input tensor during training - dropout layers are always turned off for inference. This forces the model to learn against this masked or reduced dataset. For example:"
      ],
      "metadata": {
        "id": "ZeqIBqrATcyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 4, 4)\n",
        "\n",
        "dropout = torch.nn.Dropout(p=0.4)\n",
        "print(dropout(my_tensor))\n",
        "print(dropout(my_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz_dvWEqTjHo",
        "outputId": "7341c7e3-6f33-4d8b-d1c6-522bc9ce440b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0000, 0.0000, 0.0000, 1.5199],\n",
            "         [0.4390, 1.5375, 0.4332, 1.1481],\n",
            "         [1.5698, 0.3263, 0.0000, 0.7532],\n",
            "         [1.1801, 0.0000, 1.3801, 1.1654]]])\n",
            "tensor([[[0.5754, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4390, 0.0000, 0.0000, 1.1481],\n",
            "         [1.5698, 0.3263, 0.0000, 0.0000],\n",
            "         [1.1801, 0.0000, 1.3801, 1.1654]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, you can see the effect of dropout on a sample tensor. You can use the optional p argument to set the probability of an individual weight dropping out; if you don’t it defaults to 0.5."
      ],
      "metadata": {
        "id": "6EmXEsp8Tp-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activation Functions\n",
        "\n",
        "`torch.nn.Module` has objects encapsulating all of the major activation functions including ReLU and its many variants, Tanh, Hardtanh, sigmoid, and more. It also includes other functions, such as Softmax, that are most useful at the output stage of a model.\n",
        "\n"
      ],
      "metadata": {
        "id": "B0Wb7wh9Ts7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Functions\n",
        "\n",
        "Loss functions tell us how far a model’s prediction is from the correct answer. PyTorch contains a variety of loss functions, including common MSE (mean squared error = L2 norm), Cross Entropy Loss and Negative Likelihood Loss (useful for classifiers), and others.\n",
        "\n"
      ],
      "metadata": {
        "id": "LtqSrHC1TySr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wb05JJIGT05a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}