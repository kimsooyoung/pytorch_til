{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPBNNn1v1HwvQLiG6EfeaLx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimsooyoung/pytorch_til/blob/main/youtube_series/2_introduction_to_pytorch_tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서는 PyTorch의 중심적인 데이터 추상화입니다. 이 대화형 노트북에서는 `Torch.Tensor` 클래스에 대해 자세히 설명합니다.\n",
        "\n",
        "먼저 **PyTorch** 모듈을 가져오겠습니다. 예제의 일부를 쉽게 만들 수 있도록 PyTorch의 math 모듈도 추가하겠습니다."
      ],
      "metadata": {
        "id": "6_duDyQDFFWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math"
      ],
      "metadata": {
        "id": "GBMK_WUjFMsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Tensors\n",
        "\n",
        "The simplest way to create a tensor is with the `torch.empty()` call:"
      ],
      "metadata": {
        "id": "uPosq9yARXHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(3, 4)\n",
        "print(type(x))\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRqCUrCcRYu1",
        "outputId": "19a7895a-c230-457d-908b-a7ff97afa249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s unpack what we just did:\n",
        "\n",
        "- We created a tensor using one of the numerous factory methods attached to the torch module.\n",
        "- The tensor itself is 2-dimensional, having 3 rows and 4 columns.\n",
        "- The type of the object returned is torch.Tensor, which is an alias for torch.FloatTensor; by default, PyTorch tensors are populated with 32-bit floating point numbers. (More on data types below.)\n",
        "- You will probably see some random-looking values when printing your tensor. The torch.empty() call allocates memory for the tensor, but does not initialize it with any values - so what you’re seeing is whatever was in memory at the time of allocation.\n",
        "\n",
        "A brief note about tensors and their number of dimensions, and terminology:\n",
        "- You will sometimes see a 1-dimensional tensor called a vector.\n",
        "- Likewise, a 2-dimensional tensor is often referred to as a matrix.\n",
        "- Anything with more than two dimensions is generally just called a tensor."
      ],
      "metadata": {
        "id": "dkp5LTDgRbZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More often than not, you’ll want to initialize your tensor with some value. Common cases are all zeros, all ones, or random values, and the torch module provides factory methods for all of these:"
      ],
      "metadata": {
        "id": "zIHBGKUgTaXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = torch.zeros(2, 3)\n",
        "print(zeros)\n",
        "\n",
        "ones = torch.ones(2, 3)\n",
        "print(ones)\n",
        "\n",
        "torch.manual_seed(1729)\n",
        "random = torch.rand(2, 3)\n",
        "print(random)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXNKbrKJTbqM",
        "outputId": "740a8978-bc03-4b58-bdfb-a6e9fc4a547d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[0.3126, 0.3791, 0.3087],\n",
            "        [0.0736, 0.4216, 0.0691]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Tensors and Seeding"
      ],
      "metadata": {
        "id": "adJIQPfsTjtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1729)\n",
        "random1 = torch.rand(2, 3)\n",
        "print(random1)\n",
        "\n",
        "random2 = torch.rand(2, 3)\n",
        "print(random2)\n",
        "\n",
        "torch.manual_seed(1729)\n",
        "random3 = torch.rand(2, 3)\n",
        "print(random3)\n",
        "\n",
        "random4 = torch.rand(2, 3)\n",
        "print(random4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTSdZA3QTyj9",
        "outputId": "a9d94cb3-a9f2-46a1-8f7e-8682ee512045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3126, 0.3791, 0.3087],\n",
            "        [0.0736, 0.4216, 0.0691]])\n",
            "tensor([[0.2332, 0.4047, 0.2162],\n",
            "        [0.9927, 0.4128, 0.5938]])\n",
            "tensor([[0.3126, 0.3791, 0.3087],\n",
            "        [0.0736, 0.4216, 0.0691]])\n",
            "tensor([[0.2332, 0.4047, 0.2162],\n",
            "        [0.9927, 0.4128, 0.5938]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What you should see above is that random1 and random3 carry identical values, as do random2 and random4. Manually setting the RNG’s seed resets it, so that identical computations depending on random number should, in most settings, provide identical results.\n",
        "\n",
        "For more information, see the PyTorch documentation on reproducibility."
      ],
      "metadata": {
        "id": "PPlrtbwFTzZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Shapes\n",
        "\n",
        "Often, when you’re performing operations on two or more tensors, they will need to be of the same shape - that is, having the same number of dimensions and the same number of cells in each dimension. For that, we have the `torch.*_like()` methods:\n",
        "\n"
      ],
      "metadata": {
        "id": "J4YJz_uzT4gC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2, 2, 3)\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\n",
        "empty_like_x = torch.empty_like(x)\n",
        "print(empty_like_x.shape)\n",
        "print(empty_like_x)\n",
        "\n",
        "zeros_like_x = torch.zeros_like(x)\n",
        "print(zeros_like_x.shape)\n",
        "print(zeros_like_x)\n",
        "\n",
        "ones_like_x = torch.ones_like(x)\n",
        "print(ones_like_x.shape)\n",
        "print(ones_like_x)\n",
        "\n",
        "rand_like_x = torch.rand_like(x)\n",
        "print(rand_like_x.shape)\n",
        "print(rand_like_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XlCX53dUFxv",
        "outputId": "c5f1239c-0567-44f7-c8dd-62d32d2b3a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n",
            "tensor([[[-7.9933e-08,  7.0065e-45,  0.0000e+00],\n",
            "         [ 0.0000e+00,  1.4013e-45,  0.0000e+00]],\n",
            "\n",
            "        [[ 0.0000e+00,  4.3474e-41,  1.3452e-43],\n",
            "         [ 0.0000e+00,  6.7262e-44,  0.0000e+00]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[-9.4782e-04,  3.2726e-41, -9.4778e-04],\n",
            "         [ 3.2726e-41,  8.9683e-44,  0.0000e+00]],\n",
            "\n",
            "        [[ 1.1210e-43,  0.0000e+00,  1.5706e-34],\n",
            "         [ 3.2733e-41,  1.0256e-08,  2.5783e-09]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[1., 1., 1.],\n",
            "         [1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.],\n",
            "         [1., 1., 1.]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[0.6128, 0.1519, 0.0453],\n",
            "         [0.5035, 0.9978, 0.3884]],\n",
            "\n",
            "        [[0.6929, 0.1703, 0.1384],\n",
            "         [0.4759, 0.7481, 0.0361]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first new thing in the code cell above is the use of the `.shape` property on a tensor. This property contains a list of the extent of each dimension of a tensor - in our case, x is a three-dimensional tensor with shape 2 x 2 x 3.\n",
        "\n",
        "Below that, we call the `.empty_like()`, `.zeros_like()`, `.ones_like()`, and `.rand_like()` methods. Using the `.shape` property, we can verify that each of these methods returns a tensor of identical dimensionality and extent.\n",
        "\n",
        "The last way to create a tensor that will cover is to specify its data directly from a PyTorch collection:"
      ],
      "metadata": {
        "id": "hx8lE_dIUnzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "some_constants = torch.tensor([[3.1415926, 2.71828], [1.61803, 0.0072897]])\n",
        "print(some_constants)\n",
        "\n",
        "some_integers = torch.tensor((2, 3, 5, 7, 11, 13, 17, 19))\n",
        "print(some_integers)\n",
        "\n",
        "more_integers = torch.tensor(((2, 4, 6), [3, 6, 9]))\n",
        "print(more_integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt0tBL1-UurF",
        "outputId": "e575b18e-879d-4fdb-bba4-19fc9f894a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.1416, 2.7183],\n",
            "        [1.6180, 0.0073]])\n",
            "tensor([ 2,  3,  5,  7, 11, 13, 17, 19])\n",
            "tensor([[2, 4, 6],\n",
            "        [3, 6, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using torch.tensor() is the most straightforward way to create a tensor if you already have data in a Python tuple or list. As shown above, nesting the collections will result in a multi-dimensional tensor.\n",
        "\n",
        "> `torch.tensor()` creates a copy of the data."
      ],
      "metadata": {
        "id": "h5cBKv0HVBjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Data Types\n",
        "\n",
        "Setting the datatype of a tensor is possible a couple of ways:"
      ],
      "metadata": {
        "id": "f_THcOl_VJEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones((2, 3), dtype=torch.int16)\n",
        "b = torch.rand((2, 3), dtype=torch.float64) * 20\n",
        "\n",
        "c = b.to(torch.int32)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_yJatKiVF3Z",
        "outputId": "54ffaa3f-e6de-474e-d3b1-00f8a265a948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[18,  0, 18],\n",
            "        [ 9,  3, 16]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Math & Logic with PyTorch Tensors\n",
        "\n",
        "Now that you know some of the ways to create a tensor… what can you do with them?\n",
        "\n",
        "Let’s look at basic arithmetic first, and how tensors interact with simple scalars:"
      ],
      "metadata": {
        "id": "P-TdT3QwVLpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.zeros( (2, 2) ) + 1\n",
        "twos = torch.ones( (2, 2) ) * 2\n",
        "threes = (torch.ones(2, 2) * 7 - 1) / 2\n",
        "fours = twos ** 2\n",
        "sqrts = twos ** 0.5\n",
        "\n",
        "print(ones)\n",
        "print(twos)\n",
        "print(threes)\n",
        "print(fours)\n",
        "print(sqrts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTis6NZFVzkJ",
        "outputId": "b474d546-14d1-466e-ab5d-14a46d6f384a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[3., 3.],\n",
            "        [3., 3.]])\n",
            "tensor([[4., 4.],\n",
            "        [4., 4.]])\n",
            "tensor([[1.4142, 1.4142],\n",
            "        [1.4142, 1.4142]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see above, arithmetic operations between tensors and scalars, such as addition, subtraction, multiplication, division, and exponentiation are distributed over every element of the tensor. Because the output of such an operation will be a tensor, you can chain them together with the usual operator precedence rules, as in the line where we create threes.\n",
        "\n",
        "> Similar operations between two tensors also behave like you’d intuitively expect:"
      ],
      "metadata": {
        "id": "ON4KK2EnWr04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "powers2 = twos ** torch.tensor([[1, 2], [3, 4]])\n",
        "print(powers2)\n",
        "\n",
        "fives = ones + fours\n",
        "print(fives)\n",
        "\n",
        "dozens = threes * fours\n",
        "print(dozens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzQ7NwLPXH9u",
        "outputId": "fda34897-e529-42ca-e9a3-79f68b497072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.,  4.],\n",
            "        [ 8., 16.]])\n",
            "tensor([[5., 5.],\n",
            "        [5., 5.]])\n",
            "tensor([[12., 12.],\n",
            "        [12., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In Brief: Tensor Broadcasting\n"
      ],
      "metadata": {
        "id": "D0bIA7cJXLvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand = torch.rand(2, 4)\n",
        "doubled = rand * (torch.ones(1, 4) * 2)\n",
        "\n",
        "print(rand)\n",
        "print(doubled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz9H9jg7XQPv",
        "outputId": "b69e2950-b6c1-425e-ec90-7a2ca356dc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2024, 0.5731, 0.7191, 0.4067],\n",
            "        [0.7301, 0.6276, 0.7357, 0.0381]])\n",
            "tensor([[0.4049, 1.1461, 1.4382, 0.8134],\n",
            "        [1.4602, 1.2551, 1.4715, 0.0762]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand = torch.rand(2, 4)\n",
        "temp = rand * torch.tensor([1,1,2,2])\n",
        "\n",
        "print(rand)\n",
        "print(temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2LSiGVNYHXu",
        "outputId": "a5a55d27-d3b0-4bb1-cf2f-2c545002520d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1332, 0.0023, 0.4945, 0.3857],\n",
            "        [0.9883, 0.4762, 0.7242, 0.0776]])\n",
            "tensor([[0.1332, 0.0023, 0.9890, 0.7715],\n",
            "        [0.9883, 0.4762, 1.4484, 0.1553]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> What’s the trick here? How is it we got to multiply a 2x4 tensor by a 1x4 tensor?\n",
        "\n",
        "Broadcasting is a way to perform an operation between tensors that have similarities in their shapes. In the example above, the one-row, four-column tensor is multiplied by both rows of the two-row, four-column tensor.\n",
        "\n",
        "This is an important operation in Deep Learning. The common example is multiplying a tensor of learning weights by a batch of input tensors, applying the operation to each instance in the batch separately, and returning a tensor of identical shape - just like our (2, 4) * (1, 4) example above returned a tensor of shape (2, 4).\n",
        "\n",
        "The rules for broadcasting are:\n",
        "- Each tensor must have at least one dimension - no empty tensors.\n",
        "- Comparing the dimension sizes of the two tensors, going from last to first:\n",
        "  - Each dimension must be equal, or\n",
        "  - One of the dimensions must be of size 1, or\n",
        "  - The dimension does not exist in one of the tensors\n",
        "\n",
        "> Tensors of identical shape, of course, are trivially “broadcastable”, as you saw earlier. Here are some examples of situations that honor the above rules and allow broadcasting:"
      ],
      "metadata": {
        "id": "sZcQOGF1XXc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a =     torch.ones(4, 3, 2)\n",
        "\n",
        "b = a * torch.rand(   3, 2) # 3rd & 2nd dims identical to a, dim 1 absent\n",
        "print(b)\n",
        "\n",
        "c = a * torch.rand(   3, 1) # 3rd dim = 1, 2nd dim identical to a\n",
        "print(c)\n",
        "\n",
        "d = a * torch.rand(   1, 2) # 3rd dim identical to a, 2nd dim = 1\n",
        "print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5daCFOcXZpk",
        "outputId": "43c2c45b-1f88-4df8-c232-f0dd57ccaa65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.4004, 0.9877],\n",
            "         [0.0352, 0.0905],\n",
            "         [0.4485, 0.8740]],\n",
            "\n",
            "        [[0.4004, 0.9877],\n",
            "         [0.0352, 0.0905],\n",
            "         [0.4485, 0.8740]],\n",
            "\n",
            "        [[0.4004, 0.9877],\n",
            "         [0.0352, 0.0905],\n",
            "         [0.4485, 0.8740]],\n",
            "\n",
            "        [[0.4004, 0.9877],\n",
            "         [0.0352, 0.0905],\n",
            "         [0.4485, 0.8740]]])\n",
            "tensor([[[0.2526, 0.2526],\n",
            "         [0.6923, 0.6923],\n",
            "         [0.7545, 0.7545]],\n",
            "\n",
            "        [[0.2526, 0.2526],\n",
            "         [0.6923, 0.6923],\n",
            "         [0.7545, 0.7545]],\n",
            "\n",
            "        [[0.2526, 0.2526],\n",
            "         [0.6923, 0.6923],\n",
            "         [0.7545, 0.7545]],\n",
            "\n",
            "        [[0.2526, 0.2526],\n",
            "         [0.6923, 0.6923],\n",
            "         [0.7545, 0.7545]]])\n",
            "tensor([[[0.7746, 0.2330],\n",
            "         [0.7746, 0.2330],\n",
            "         [0.7746, 0.2330]],\n",
            "\n",
            "        [[0.7746, 0.2330],\n",
            "         [0.7746, 0.2330],\n",
            "         [0.7746, 0.2330]],\n",
            "\n",
            "        [[0.7746, 0.2330],\n",
            "         [0.7746, 0.2330],\n",
            "         [0.7746, 0.2330]],\n",
            "\n",
            "        [[0.7746, 0.2330],\n",
            "         [0.7746, 0.2330],\n",
            "         [0.7746, 0.2330]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Here are some examples of attempts at broadcasting that will fail"
      ],
      "metadata": {
        "id": "0SgPNTaAYlp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a =     torch.ones(4, 3, 2)\n",
        "\n",
        "# b = a * torch.rand(4, 3)    # dimensions must match last-to-first\n",
        "# c = a * torch.rand(   2, 3) # both 3rd & 2nd dims different\n",
        "# d = a * torch.rand((0, ))   # can't broadcast with an empty tensor"
      ],
      "metadata": {
        "id": "mPEOFYgCYulM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More Math with Tensors\n",
        "\n",
        "> PyTorch tensors have over three hundred operations that can be performed on them. Here is a small sample from some of the major categories of operations:"
      ],
      "metadata": {
        "id": "t-KFpueeYwfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# common functions\n",
        "a = torch.rand(2, 4) * 2 - 1\n",
        "print('Common functions:')\n",
        "print(torch.abs(a))\n",
        "print(torch.ceil(a))\n",
        "print(torch.floor(a))\n",
        "print(torch.clamp(a, -0.5, 0.5))\n",
        "\n",
        "# trigonometric functions and their inverses\n",
        "angles = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "sines = torch.sin(angles)\n",
        "inverses = torch.asin(sines)\n",
        "print('\\nSine and arcsine:')\n",
        "print(angles)\n",
        "print(sines)\n",
        "print(inverses)\n",
        "\n",
        "# bitwise operations\n",
        "print('\\nBitwise XOR:')\n",
        "b = torch.tensor([1, 5, 11])\n",
        "c = torch.tensor([2, 7, 10])\n",
        "print(torch.bitwise_xor(b, c))\n",
        "\n",
        "# comparisons:\n",
        "print('\\nBroadcasted, element-wise equality comparison:')\n",
        "d = torch.tensor([[1., 2.], [3., 4.]])\n",
        "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
        "print(torch.eq(d, e)) # returns a tensor of type bool\n",
        "\n",
        "# reductions:\n",
        "print('\\nReduction ops:')\n",
        "print(torch.max(d))        # returns a single-element tensor\n",
        "print(torch.max(d).item()) # extracts the value from the returned tensor\n",
        "print(torch.mean(d))       # average\n",
        "print(torch.std(d))        # standard deviation\n",
        "print(torch.prod(d))       # product of all numbers\n",
        "print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 2]))) # filter unique elements\n",
        "\n",
        "# vector and linear algebra operations\n",
        "v1 = torch.tensor([1., 0., 0.])         # x unit vector\n",
        "v2 = torch.tensor([0., 1., 0.])         # y unit vector\n",
        "m1 = torch.rand(2, 2)                   # random matrix\n",
        "m2 = torch.tensor([[3., 0.], [0., 3.]]) # three times identity matrix\n",
        "\n",
        "print('\\nVectors & Matrices:')\n",
        "print(torch.cross(v2, v1)) # negative of z unit vector (v1 x v2 == -v2 x v1)\n",
        "print(m1)\n",
        "m3 = torch.matmul(m1, m2)\n",
        "print(m3)                  # 3 times m1\n",
        "print(torch.svd(m3))       # singular value decomposition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvztMlHbY3Mp",
        "outputId": "52fc4d55-dd1f-428b-a767-fbf4357b4b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common functions:\n",
            "tensor([[0.1018, 0.2531, 0.8823, 0.0156],\n",
            "        [0.0921, 0.0792, 0.3893, 0.6054]])\n",
            "tensor([[-0., 1., 1., -0.],\n",
            "        [1., 1., -0., -0.]])\n",
            "tensor([[-1.,  0.,  0., -1.],\n",
            "        [ 0.,  0., -1., -1.]])\n",
            "tensor([[-0.1018,  0.2531,  0.5000, -0.0156],\n",
            "        [ 0.0921,  0.0792, -0.3893, -0.5000]])\n",
            "\n",
            "Sine and arcsine:\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
            "tensor([0.0000, 0.7854, 1.5708, 0.7854])\n",
            "\n",
            "Bitwise XOR:\n",
            "tensor([3, 2, 1])\n",
            "\n",
            "Broadcasted, element-wise equality comparison:\n",
            "tensor([[ True, False],\n",
            "        [False, False]])\n",
            "\n",
            "Reduction ops:\n",
            "tensor(4.)\n",
            "4.0\n",
            "tensor(2.5000)\n",
            "tensor(1.2910)\n",
            "tensor(24.)\n",
            "tensor([1, 2])\n",
            "\n",
            "Vectors & Matrices:\n",
            "tensor([ 0.,  0., -1.])\n",
            "tensor([[0.3285, 0.5655],\n",
            "        [0.0065, 0.7765]])\n",
            "tensor([[0.9856, 1.6966],\n",
            "        [0.0196, 2.3296]])\n",
            "torch.return_types.svd(\n",
            "U=tensor([[ 0.6345,  0.7729],\n",
            "        [ 0.7729, -0.6345]]),\n",
            "S=tensor([2.9475, 0.7677]),\n",
            "V=tensor([[ 0.2173,  0.9761],\n",
            "        [ 0.9761, -0.2173]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Altering Tensors in Place\n",
        "\n",
        "Most binary operations on tensors will return a third, new tensor. When we say c = a * b (where a and b are tensors), the new tensor c will occupy a region of memory distinct from the other tensors.\n",
        "\n",
        "There are times, though, that you may wish to alter a tensor in place - for example, if you’re doing an element-wise computation where you can discard intermediate values. For this, most of the math functions have a version with an appended underscore (_) that will alter a tensor in place.\n",
        "\n",
        "> 별도 변수 저장 없이 바로 해당 변수에 연산 결과 덮어씌우는 방법"
      ],
      "metadata": {
        "id": "xYNHYrz_Y_k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "print('a:')\n",
        "print(a)\n",
        "print(torch.sin(a))   # this operation creates a new tensor in memory\n",
        "print(a)              # a has not changed\n",
        "\n",
        "b = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "print('\\nb:')\n",
        "print(b)\n",
        "print(torch.sin_(b))  # note the underscore\n",
        "print(b)              # b has changed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8INqL_0wZqAB",
        "outputId": "c75cf4eb-aeaa-418b-cc83-182893320620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "\n",
            "b:\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that these in-place arithmetic functions are methods on the torch.Tensor object, not attached to the torch module like many other functions (e.g., `torch.sin()`). As you can see from `a.add_(b)`, the calling tensor is the one that gets changed in place.\n",
        "\n",
        "There is another option for placing the result of a computation in an existing, allocated tensor. Many of the methods and functions we’ve seen so far - including creation methods! - have an out argument that lets you specify a tensor to receive the output. If the out tensor is the correct shape and dtype, this can happen without a new memory allocation:"
      ],
      "metadata": {
        "id": "s05xRoxyaCF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(2, 2)\n",
        "b = torch.rand(2, 2)\n",
        "c = torch.zeros(2, 2)\n",
        "old_id = id(c)\n",
        "\n",
        "print(c)\n",
        "d = torch.matmul(a, b, out=c)\n",
        "print(c)                # contents of c have changed\n",
        "\n",
        "assert c is d           # test c & d are same object, not just containing equal values\n",
        "assert id(c) == old_id  # make sure that our new c is the same object as the old one\n",
        "\n",
        "torch.rand(2, 2, out=c) # works for creation too!\n",
        "print(c)                # c has changed again\n",
        "assert id(c) == old_id  # still the same object!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNLSgyOaaOSH",
        "outputId": "2d8dde01-438f-4b16-a961-9efa4e999421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[0.5991, 0.7677],\n",
            "        [0.8968, 1.2237]])\n",
            "tensor([[0.4704, 0.6077],\n",
            "        [0.4757, 0.5874]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copying Tensors\n"
      ],
      "metadata": {
        "id": "5YZJuQNvaPbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(2, 2)\n",
        "b = a\n",
        "\n",
        "a[0][1] = 561  # we change a...\n",
        "print(b)       # ...and b is also altered"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3m4-hKGaSG9",
        "outputId": "aef7143e-2921-4b2f-ff1c-a68e3fadcbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  1., 561.],\n",
            "        [  1.,   1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(2, 2)\n",
        "b = a.clone()\n",
        "\n",
        "assert b is not a      # different objects in memory...\n",
        "print(torch.eq(a, b))  # ...but still with the same contents!\n",
        "\n",
        "a[0][1] = 561          # a changes...\n",
        "print(b)               # ...but b is still all ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDc_psz3aS1F",
        "outputId": "28d72e3f-1248-4481-b9a3-f043a7febd0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[True, True],\n",
            "        [True, True]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is an important thing to be aware of when using ``clone()``. If your source tensor has autograd, enabled then so will the clone. This will be covered more deeply in the video on autograd, but if you want the light version of the details, continue on."
      ],
      "metadata": {
        "id": "wmfNRcV0aZOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(2, 2, requires_grad=True) # turn on autograd\n",
        "print(a)\n",
        "\n",
        "b = a.clone()\n",
        "print(b)\n",
        "\n",
        "c = a.detach().clone()\n",
        "print(c)\n",
        "\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdRcGR2zagtR",
        "outputId": "010d0052-87c9-4641-c460-c7217711aa60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4363, 0.6339],\n",
            "        [0.3208, 0.4323]], requires_grad=True)\n",
            "tensor([[0.4363, 0.6339],\n",
            "        [0.3208, 0.4323]], grad_fn=<CloneBackward0>)\n",
            "tensor([[0.4363, 0.6339],\n",
            "        [0.3208, 0.4323]])\n",
            "tensor([[0.4363, 0.6339],\n",
            "        [0.3208, 0.4323]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What’s happening here?\n",
        "\n",
        "- We create a with requires_grad=True turned on. We haven’t covered this optional argument yet, but will during the unit on autograd.\n",
        "- When we print a, it informs us that the property requires_grad=True - this means that autograd and computation history tracking are turned on.\n",
        "- We clone a and label it b. When we print b, we can see that it’s tracking its computation history - it has inherited a’s autograd settings, and added to the computation history.\n",
        "- We clone a into c, but we call detach() first.\n",
        "- Printing c, we see no computation history, and no requires_grad=True.\n",
        "\n",
        "The `detach()` method detaches the tensor from its computation history. It says, “do whatever comes next as if autograd was off.” It does this without changing a - you can see that when we print a again at the end, it retains its `requires_grad=True` property."
      ],
      "metadata": {
        "id": "zLkCmxcTa1Ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving to GPU\n",
        "\n",
        "One of the major advantages of PyTorch is its robust acceleration on CUDA-compatible Nvidia GPUs. (“CUDA” stands for Compute Unified Device Architecture, which is Nvidia’s platform for parallel computing.) So far, everything we’ve done has been on CPU. How do we move to the faster hardware?\n",
        "\n",
        "> First, we should check whether a GPU is available, with the `is_available()` method."
      ],
      "metadata": {
        "id": "2JzskBqhbM69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"We have a GPU!!\")\n",
        "else:\n",
        "  print(\"Sorry, CPU only...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbuxBHGwbXDi",
        "outputId": "de990daa-7b24-470d-a456-6dc1a85f5ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have a GPU!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we’ve determined that one or more GPUs is available, we need to put our data someplace where the GPU can see it. Your CPU does computation on data in your computer’s RAM. Your GPU has dedicated memory attached to it. Whenever you want to perform a computation on a device, you must move all the data needed for that computation to memory accessible by that device. (Colloquially, “moving the data to memory accessible by the GPU” is shorted to, “moving the data to the GPU”.)\n",
        "\n",
        "> There are multiple ways to get your data onto your target device. You may do it at creation time:\n",
        "\n"
      ],
      "metadata": {
        "id": "xYhcG6P2c7w_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  gpu_rand = torch.rand(2, 2, device='cuda')\n",
        "  print(gpu_rand)\n",
        "else:\n",
        "  print(\"Sorry, CPU only...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIZyO7kOdA8t",
        "outputId": "18dee831-4858-41f6-9e21-f6eae0db98d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3344, 0.2640],\n",
            "        [0.2119, 0.0582]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, new tensors are created on the CPU, so we have to specify when we want to create our tensor on the GPU with the optional device argument. You can see when we print the new tensor, PyTorch informs us which device it’s on (if it’s not on CPU).\n",
        "\n",
        "You can query the number of GPUs with torch.cuda.device_count(). If you have more than one GPU, you can specify them by index: device='cuda:0', device='cuda:1', etc.\n",
        "\n",
        "As a coding practice, specifying our devices everywhere with string constants is pretty fragile. In an ideal world, your code would perform robustly whether you’re on CPU or GPU hardware. You can do this by creating a device handle that can be passed to your tensors instead of a string:\n",
        "\n"
      ],
      "metadata": {
        "id": "1_xeb5tMdLsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    my_device = torch.device('cuda')\n",
        "else:\n",
        "    my_device = torch.device('cpu')\n",
        "print('Device: {}'.format(my_device))\n",
        "\n",
        "x = torch.rand(2, 2, device=my_device)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ_Yb5SLe2Or",
        "outputId": "82bfd95a-13e3-4216-9cc2-d059b0fcd5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "tensor([[0.0024, 0.6778],\n",
            "        [0.2441, 0.6812]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have an existing tensor living on one device, you can move it to another with the to() method. The following line of code creates a tensor on CPU, and moves it to whichever device handle you acquired in the previous cell."
      ],
      "metadata": {
        "id": "NWWxWeVNe3v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.rand(2, 2)\n",
        "y = y.to(my_device)"
      ],
      "metadata": {
        "id": "m1dLjsEOe8eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to know that in order to do computation involving two or more tensors, all of the tensors must be on the same device. The following code will throw a runtime error, regardless of whether you have a GPU device available:"
      ],
      "metadata": {
        "id": "qQzEs1YNe9J4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 2, device='cuda')\n",
        "y = torch.rand(2, 2, device='cuda')\n",
        "z = x + y  # exception will be thrown"
      ],
      "metadata": {
        "id": "vaoM85ClfBk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manipulating Tensor Shapes\n",
        "\n",
        "> Sometimes, you’ll need to change the shape of your tensor. Below, we’ll look at a few common cases, and how to handle them.\n",
        "\n",
        "## Changing the Number of Dimensions\n",
        "\n",
        "One case where you might need to change the number of dimensions is passing a single instance of input to your model. PyTorch models generally expect batches of input.\n",
        "\n",
        "For example, imagine having a model that works on `3 x 226 x 226` images - a 226-pixel square with 3 color channels. When you load and transform it, you’ll get a tensor of shape (3, 226, 226). Your model, though, is expecting input of shape (N, 3, 226, 226), where N is the number of images in the batch. So how do you make a batch of one?"
      ],
      "metadata": {
        "id": "8WCfYZOhfCae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(3, 226, 226)\n",
        "b = a.unsqueeze(0)\n",
        "\n",
        "print(a.shape)\n",
        "print(b.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88n-95wvfQwn",
        "outputId": "cf249614-12ba-45e8-d473-e3f78957eb61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 226, 226])\n",
            "torch.Size([1, 3, 226, 226])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `unsqueeze()` method adds a dimension of extent 1. `unsqueeze(0)` adds it as a new zeroth dimension - now you have a batch of one!\n",
        "\n",
        "So if that’s unsqueezing? What do we mean by squeezing? We’re taking advantage of the fact that any dimension of extent 1 does not change the number of elements in the tensor."
      ],
      "metadata": {
        "id": "nZFW7_XyfvjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.rand(1, 1, 1, 1, 1)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO020WRvfyX0",
        "outputId": "0342b2bc-2d9e-4a06-bde9-196d5e9d2099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[[0.5088]]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continuing the example above, let’s say the model’s output is a 20-element vector for each input. You would then expect the output to have shape (N, 20), where N is the number of instances in the input batch. That means that for our single-input batch, we’ll get an output of shape (1, 20).\n",
        "\n",
        "What if you want to do some non-batched computation with that output - something that’s just expecting a 20-element vector?"
      ],
      "metadata": {
        "id": "PGqgONvCf12r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(1, 20)\n",
        "print(a.shape)\n",
        "print(a)\n",
        "\n",
        "b = a.squeeze(0)\n",
        "print(b.shape)\n",
        "print(b)\n",
        "\n",
        "c = torch.rand(2, 2)\n",
        "print(c.shape)\n",
        "\n",
        "d = c.squeeze(0)\n",
        "print(d.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSofD9FKgNJi",
        "outputId": "54a94029-b346-4c0d-f076-7b84e4639007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 20])\n",
            "tensor([[0.3142, 0.8068, 0.6503, 0.4621, 0.6882, 0.7282, 0.9156, 0.4836, 0.1451,\n",
            "         0.7946, 0.4126, 0.1625, 0.9214, 0.2327, 0.5813, 0.7089, 0.3735, 0.9389,\n",
            "         0.3442, 0.9211]])\n",
            "torch.Size([20])\n",
            "tensor([0.3142, 0.8068, 0.6503, 0.4621, 0.6882, 0.7282, 0.9156, 0.4836, 0.1451,\n",
            "        0.7946, 0.4126, 0.1625, 0.9214, 0.2327, 0.5813, 0.7089, 0.3735, 0.9389,\n",
            "        0.3442, 0.9211])\n",
            "torch.Size([2, 2])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dimension value가 1인 경우에만 squeeze를 할 수 있다."
      ],
      "metadata": {
        "id": "Wci3JPVogUX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another place you might use unsqueeze() is to ease broadcasting. Recall the example above where we had the following code:"
      ],
      "metadata": {
        "id": "FRADF6BpgZUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(4, 3, 2)\n",
        "b = torch.rand(   3)     # trying to multiply a * b will give a runtime error\n",
        "c = b.unsqueeze(1)       # change to a 2-dimensional tensor, adding new dim at the end\n",
        "print(c.shape)\n",
        "print(a * c)             # broadcasting works again!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg5rR46WghQz",
        "outputId": "b6172236-3af4-46c2-b69c-eac1b18c610c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1])\n",
            "tensor([[[0.9906, 0.9906],\n",
            "         [0.0350, 0.0350],\n",
            "         [0.0411, 0.0411]],\n",
            "\n",
            "        [[0.9906, 0.9906],\n",
            "         [0.0350, 0.0350],\n",
            "         [0.0411, 0.0411]],\n",
            "\n",
            "        [[0.9906, 0.9906],\n",
            "         [0.0350, 0.0350],\n",
            "         [0.0411, 0.0411]],\n",
            "\n",
            "        [[0.9906, 0.9906],\n",
            "         [0.0350, 0.0350],\n",
            "         [0.0411, 0.0411]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The squeeze() and unsqueeze() methods also have in-place versions, squeeze_() and unsqueeze_():"
      ],
      "metadata": {
        "id": "zEmhz-7RgiKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_me = torch.rand(3, 226, 226)\n",
        "print(batch_me.shape)\n",
        "batch_me.unsqueeze_(0)\n",
        "print(batch_me.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4zOlN5Ngkdq",
        "outputId": "62d59f57-4b47-40b6-dc1d-cc39699479ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 226, 226])\n",
            "torch.Size([1, 3, 226, 226])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes you’ll want to change the shape of a tensor more radically, while still preserving the number of elements and their contents. One case where this happens is at the interface between a convolutional layer of a model and a linear layer of the model - this is common in image classification models. A convolution kernel will yield an output tensor of shape features x width x height, but the following linear layer expects a 1-dimensional input. reshape() will do this for you, provided that the dimensions you request yield the same number of elements as the input tensor has:\n",
        "\n",
        "> 완전 일자로 피는 극단적인 경우,reshape() 사용"
      ],
      "metadata": {
        "id": "Pns6V2-HglOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output3d = torch.rand(6, 20, 20)\n",
        "print(output3d.shape)\n",
        "\n",
        "input1d = output3d.reshape(6 * 20 * 20)\n",
        "print(input1d.shape)\n",
        "\n",
        "# can also call it as a method on the torch module:\n",
        "print(torch.reshape(output3d, (6 * 20 * 20,)).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXDOFJDOgvqq",
        "outputId": "5c32bc9b-8a96-48e4-c9aa-e39a7287a392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 20, 20])\n",
            "torch.Size([2400])\n",
            "torch.Size([2400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NumPy Bridge\n",
        "\n",
        "In the section above on broadcasting, it was mentioned that PyTorch’s broadcast semantics are compatible with NumPy’s - but the kinship between PyTorch and NumPy goes even deeper than that.\n",
        "\n",
        "If you have existing ML or scientific code with data stored in NumPy ndarrays, you may wish to express that same data as PyTorch tensors, whether to take advantage of PyTorch’s GPU acceleration, or its efficient abstractions for building ML models. It’s easy to switch between ndarrays and PyTorch tensors:\n",
        "\n",
        "> numpy => torch"
      ],
      "metadata": {
        "id": "n4dueMW5g2Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "numpy_array = np.ones((2, 3))\n",
        "print(numpy_array)\n",
        "\n",
        "pytorch_tensor = torch.from_numpy(numpy_array)\n",
        "print(pytorch_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrwZZ24dhShR",
        "outputId": "75cde9b5-5400-4541-e867-ae8aafe65467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]]\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch creates a tensor of the same shape and containing the same data as the NumPy array, going so far as to keep NumPy’s default 64-bit float data type.\n",
        "\n",
        "The conversion can just as easily go the other way:\n",
        "\n",
        "> torch => numpy"
      ],
      "metadata": {
        "id": "uoIg3brMhTVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_rand = torch.rand(2, 3)\n",
        "print(pytorch_rand)\n",
        "\n",
        "numpy_rand = pytorch_rand.numpy()\n",
        "print(numpy_rand)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urZ1s9Y8hcVy",
        "outputId": "8086044c-e925-406a-e5b1-97d922113312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9627, 0.7905, 0.6169],\n",
            "        [0.6786, 0.8231, 0.1066]])\n",
            "[[0.9626979  0.7904784  0.61689967]\n",
            " [0.6785838  0.8230716  0.1065619 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to know that these converted objects are using the same underlying memory as their source objects, meaning that changes to one are reflected in the other:\n",
        "\n",
        "> 메모리를 공유하므로 numpy 변수 바꾸면 torch 변수도 바뀜에 유의!"
      ],
      "metadata": {
        "id": "FANojCQ1hdKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array[1, 1] = 23\n",
        "print(pytorch_tensor)\n",
        "\n",
        "pytorch_rand[1, 1] = 17\n",
        "print(numpy_rand)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vRNr2ychn-q",
        "outputId": "4e48f31b-cee7-4a31-9c2a-b57d2f1dcf25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  1.,  1.],\n",
            "        [ 1., 23.,  1.]], dtype=torch.float64)\n",
            "[[ 0.9626979   0.7904784   0.61689967]\n",
            " [ 0.6785838  17.          0.1065619 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8wTqFKPhoyR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}